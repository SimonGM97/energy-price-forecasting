import sys
import os

# Add the energy-price-forecasting directory to the Python path
project_root = os.path.abspath(os.path.join(os.getcwd(), '..', 'energy-price-forecasting'))
sys.path.append(project_root)

import pandas as pd
import json
from pprint import pformat

from modeling.model import Model
from utils.s3_utils import load_from_s3, write_to_s3
from config.config import BUCKET


def lambda_handler(
    event: dict, 
    context: dict = None
) -> dict:
    """
    :param `event`: (dict) Data sent during lambda function invocation.
    :param `context`: (dict) Generated by the platform and contains information about the underlying infrastructure
        and execution environment, such as allowed runtime and memory.
    """
    # Load X_test
    X_test: pd.DataFrame = load_from_s3(path=f"{BUCKET}/datasets/X_test.csv")

    # Load champion Model
    champion: Model = Model()
    champion.load(champion=True)

    # Forecast test data
    test_pred = champion.predict(
        forecast_features=X_test, 
        forecast_dates=X_test.index
    )

    # Build test_pred pd.Series
    test_pred = pd.Series(
        data=test_pred,
        index=X_test.index
    )

    # Save test_pred
    write_to_s3(
        asset=test_pred,
        path=f"{BUCKET}/inferences/test_pred.csv"
    )

    return {
        'statusCode': 200,
        'body': json.dumps('Inference job ran successfully!')
    }


# conda deactivate
# source .price_forecasting_env/bin/activate
# .price_forecasting_env/bin/python inference/inference.py
if __name__ == "__main__":
    # Run lambda function
    lambda_handler(event=None, context=None)